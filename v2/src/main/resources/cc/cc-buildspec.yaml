version: 0.2

phases:
  pre_build:
    commands:
      - apt-get update
      - apt-get install -y git
      - rm -rf capillary-cloud-tf/stacks/*
      - cp ${CODEBUILD_SRC_DIR_DEPLOYMENT_CONTEXT}/deploymentcontext.json capillary-cloud-tf/deploymentcontext.json
      - cp -r $CODEBUILD_SRC_DIR_STACK/$STACK_SUBDIRECTORY capillary-cloud-tf/stacks/$STACK_NAME
      - cp -r $CODEBUILD_SRC_DIR_STACK/$STACK_SUBDIRECTORY/schema capillary-cloud-tf/schema
      - cp -r $CODEBUILD_SRC_DIR_STACK/$STACK_SUBDIRECTORY/seed_data capillary-cloud-tf/seed_data
      - if [ -d "$CODEBUILD_SRC_DIR_STACK/$STACK_SUBDIRECTORY/database_views" ]; then cp -r $CODEBUILD_SRC_DIR_STACK/$STACK_SUBDIRECTORY/database_views capillary-cloud-tf/database_views; fi
      - python3 capillary-cloud-tf/$CLOUD_TF_PROVIDER/scripts/merge_overrides.py
      - cd capillary-cloud-tf/$CLOUD_TF_PROVIDER/
      - sed -i s/STATE_BUCKET/$TF_VAR_cc_tf_state_bucket/g backend.tf
      - sed -i s/STATE_REGION/$TF_VAR_cc_tf_state_region/g backend.tf
      - sed -i s/STATE_DYNAMO_TABLE/$TF_VAR_cc_tf_dynamo_table/g backend.tf
      - terraform init
      - if terraform workspace select $CLUSTER_ID; then echo "workspace exists"; else terraform workspace new $CLUSTER_ID; fi
  build:
    commands:
      - terraform apply -target module.infra -auto-approve -no-color -parallelism=20
      - terraform apply -target module.iam -target module.application -target module.disaster-recovery -auto-approve -no-color -parallelism=20
  post_build:
    commands:
      - python3 scripts/report.py
artifacts:
  files:
    - capillary-cloud-tf/$CLOUD_TF_PROVIDER/fetched_builds/**/*
    - capillary-cloud-tf/$CLOUD_TF_PROVIDER/*.json
    - v2/cc-integration-tests/target/site/*.html
cache:
  paths:
    - capillary-cloud-tf/$CLOUD_TF_PROVIDER/.terraform/**/*